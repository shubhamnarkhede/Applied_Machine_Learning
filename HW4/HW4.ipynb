{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1 – Programming (80 points):**\n",
    "In this programming problem, you will get familiar with building a neural network using\n",
    "backpropagation. You will write a program that learns how to recognize the handwritten digits using\n",
    "stochastic gradient descent and the MNIST training data.\n",
    "The MNIST database (Modified National Institute of Standards and Technology database is a large\n",
    "database of handwritten digits that is commonly used for training various image processing systems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Step 1 Data Acquisition and Visualization (10 pts):**\n",
    "\n",
    "\n",
    "In this step, you need to:\n",
    "(a) Download the “MNIST” dataset and extract the files. You will get four files with extension .gz\n",
    "\n",
    "(e.g., train-images-idx3-ubyte.gz). You can use the provided function read_idx below to read in\n",
    "the dataset. As its official description, the dataset is split into 60000 training images and 10000\n",
    "images. The four file corresponds to the training images, training labels, testing images and\n",
    "testing labels. You need to print out their shape to finish this step. (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "def read_idx(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Images Shape: (60000, 28, 28)\n",
      "Training Labels Shape: (60000,)\n",
      "Test Images Shape: (10000, 28, 28)\n",
      "Test Labels Shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# File paths for the dataset\n",
    "train_images_path = 'data/train-images-idx3-ubyte.gz'\n",
    "train_labels_path = 'data/train-labels-idx1-ubyte.gz'\n",
    "test_images_path = 'data/t10k-images-idx3-ubyte.gz'\n",
    "test_labels_path = 'data/t10k-labels-idx1-ubyte.gz'\n",
    "\n",
    "# Read the dataset files\n",
    "train_images = read_idx(train_images_path)\n",
    "train_labels = read_idx(train_labels_path)\n",
    "test_images = read_idx(test_images_path)\n",
    "test_labels = read_idx(test_labels_path)\n",
    "\n",
    "# Reshape and print the shapes of the datasets\n",
    "print(\"Training Images Shape:\", train_images.shape)\n",
    "print(\"Training Labels Shape:\", train_labels.shape)\n",
    "print(\"Test Images Shape:\", test_images.shape)\n",
    "print(\"Test Labels Shape:\", test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B) To further understand what the dataset is, you need to use the ‘matplotlib’ library to print out a \n",
    "random data with code plt.imshow together with its label.(5 pts) You will see something like \n",
    "this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAOg0lEQVR4nO3cWYiWdf/H8e/tWE5qibm0Z4htQ0arFhhZRGZ1oCgEKTUeWJSGBO2RWgdF0EabBS0mEUFqESRZUVNG1jRYkalkkpHaom3aauT9HDz/vtR/fGp+d7M40+sFHThcn7l+8zzp22vMq1KtVqsBABHRq6sPAMCuQxQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRTokdavXx+VSiVuu+22dvucTU1NUalUoqmpqd0+J+xqRIFdxvz586NSqURLS0tXH6VDzJ07NyqVSqt/6uvru/pokHp39QHg32bevHnRv3///HFdXV0Xngb+TBSgk02ePDkGDx7c1ceAnfLtI7qV7du3x+zZs+P444+PAQMGRL9+/eKUU06JV1555X9u7rzzzhg2bFjsscceceqpp8bKlStbXbNmzZqYPHly7L333lFfXx8nnHBCPPvss397nh9//DHWrFkTW7ZsafPXUK1WY+vWreEFxeyKRIFuZevWrfHQQw/F2LFj49Zbb425c+fG5s2bY9y4cfHuu++2un7BggVx9913x4wZM+Laa6+NlStXxumnnx5ffPFFXvPBBx/ESSedFKtXr45rrrkmbr/99ujXr19MmDAhnn766b88T3Nzcxx55JFx7733tvlrGD58eAwYMCD23HPPmDp16p/OAl3Nt4/oVgYOHBjr16+P3XffPT82ffr0OOKII+Kee+6Jhx9++E/Xf/TRR7F27do44IADIiLirLPOitGjR8ett94ad9xxR0REzJo1Kw4++OB4++23o0+fPhERcemll8aYMWPi6quvjokTJ7bb2WfOnBknn3xy9OnTJ5YtWxb33XdfNDc3R0tLS+y1117tch/4J0SBbqWuri7/YHbHjh3x7bffxo4dO+KEE06IFStWtLp+woQJGYSIiFGjRsXo0aNjyZIlcccdd8TXX38dL7/8ctx0002xbdu22LZtW147bty4mDNnTmzcuPFPn+OPxo4d2+ZvA82aNetPP540aVKMGjUqpkyZEvfff39cc801bfo80JF8+4hu57HHHoujjz466uvrY9CgQTFkyJB47rnn4rvvvmt17aGHHtrqY4cddlisX78+Iv77JFGtVuOGG26IIUOG/OmfOXPmRETEl19+2WFfy/nnnx/77rtvvPTSSx12DyjhSYFu5fHHH4/GxsaYMGFCXHnllTF06NCoq6uLW265JdatW1f8+Xbs2BEREVdccUWMGzdup9eMGDHiH5357xx00EHx9ddfd+g9oK1EgW5l4cKFMXz48Fi8eHFUKpX8+O+/q///1q5d2+pjH374YRxyyCER8d8/9I2I2G233eKMM85o/wP/jWq1GuvXr49jjz220+8NO+PbR3Qrv/95wh+/j//WW2/F8uXLd3r9M888Exs3bswfNzc3x1tvvRXjx4+PiIihQ4fG2LFj48EHH4zPPvus1X7z5s1/eZ6S/yR1Z59r3rx5sXnz5jjrrLP+dg+dwZMCu5xHHnkknn/++VYfnzVrVpx77rmxePHimDhxYpxzzjnx8ccfxwMPPBANDQ3x/ffft9qMGDEixowZE5dcckn88ssvcdddd8WgQYPiqquuymvuu+++GDNmTIwcOTKmT58ew4cPjy+++CKWL18eGzZsiPfee+9/nrW5uTlOO+20mDNnTsydO/cvv65hw4bFeeedFyNHjoz6+vp4/fXX48knn4xjjjkmLr744rb/DwQdSBTY5cybN2+nH29sbIzGxsb4/PPP48EHH4ylS5dGQ0NDPP744/HUU0/t9EV1F1xwQfTq1Svuuuuu+PLLL2PUqFFx7733xn777ZfXNDQ0REtLS9x4440xf/78+Oqrr2Lo0KFx7LHHxuzZs9vt65oyZUq88cYbsWjRovj5559j2LBhcdVVV8X1118fffv2bbf7wD9RqfprlQD8H3+mAEASBQCSKACQRAGAJAoAJFEAILX57yn88ZUCAHQ/bfkbCJ4UAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQenf1AYBdS2NjY/Fmv/32K95MnTq1eBMR0dDQUNOu1HXXXVe8ueWWWzrgJJ3LkwIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAFKlWq1W23RhpdLRZwH+wrRp04o3119/ffFm2LBhxZtevXre7y9fffXV4s3pp5/eASdpP2355b7n/T8JQM1EAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAg9e7qA0B3dtRRRxVvLr300pruNX369OJNT3xR3YoVK4o3I0eOLN6sXLmyeNMT9Lx/YwComSgAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACQvxKNH2m233Yo3d999d/Fm0qRJxZtBgwYVbzpTU1NT8eb9998v3sybN694ExGxZcuW4s3AgQOLNx999FHxpifwpABAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKAKRKtVqttunCSqWjzwLtZq+99irefPPNN8WbWn5etPGnXCtLliwp3tx4443Fm9WrVxdvfvjhh+INna8t/+55UgAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQOrd1Qege+rfv3/xpqGhoaZ7TZ48uXhz4okn1nSvzjBjxoyadq+99lrxZtWqVTXdi38vTwoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEheiEeMGDGieHPnnXcWb84+++ziTU+0YsWKmnZebkdn8KQAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYDkhXg9zB577FG8mTZtWvHmuOOOK97U6rfffivefPLJJ8Wbm266qXhTqVSKN++8807xBjqLJwUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACBVqtVqtU0X1vA2SDrfI488Ury58MILO+Ak7WfTpk3Fm4aGhuLNtm3bijfQnbTll3tPCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASF6I18OsWrWqeHP44Yd3wEm61vbt24s348ePL940NTUVb6CreCEeAEVEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgeSFeD3P55ZcXb6688srizb777lu86Ylee+214s3NN99c071eeOGFmnbwOy/EA6CIKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJC/EI/r27Vu8ueiii4o3w4cPL95ERPTr169409jYWNO9StXy82L79u013euXX34p3lx22WXFmwULFhRv6B68EA+AIqIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJC8EI9dXl1dXfFmn3326YCTtLZhw4biTRt/yrWLn3/+uXgzc+bM4s2jjz5avKHzeSEeAEVEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIAqXdXHwD+zm+//Va82bRpUwecpLWGhobizZlnnlnTva677rrizZAhQ4o3Rx99dPGGnsOTAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAUqVarVbbdGGl0tFnAf7Cp59+WrzZf//9izejR48u3rS0tBRv6Hxt+eXekwIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAFLvrj4AdGejRo0q3px88sk13Wvw4ME17aCEJwUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACQvxCt0xBFHdMp91q1bV9Pu119/beeTtJ8DDzywpl3//v2LN/X19cWb2bNnF28mTpxYvNmxY0fxplarVq0q3mzcuLEDTkJ34UkBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgDJC/EKvfnmm8WbPffcs3izaNGi4k1ExE8//VTTrjOceuqpNe0OOuigdj5J97RixYrizf3331+82ZVfqkjH86QAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgCkSrVarbbpwkqlo8/SLSxdurR4c8YZZ3TASdgV9OpV/vuqpqammu61cOHC4s0TTzxRvPnmm2+KN3QPbfnl3pMCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSF+J1gssvv7x406dPn0671+DBg2u6V09Ty8sOly1bVrxpaWkp3kREvPjiizXt4HdeiAdAEVEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEheiAfwL+GFeAAUEQUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgNS7rRdWq9WOPAcAuwBPCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgCk/wDE5LcO5Ftp7QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Get a random index to select a random image and its label\n",
    "random_index = random.randint(0, len(train_images))\n",
    "\n",
    "# Select the image and its label\n",
    "random_image = train_images[random_index]\n",
    "random_label = train_labels[random_index]\n",
    "\n",
    "# Reshape the image into a 28x28 format (assuming it's the MNIST image size)\n",
    "random_image = random_image.reshape(28, 28)\n",
    "\n",
    "# Plot the image using plt.imshow\n",
    "plt.imshow(random_image, cmap='gray')\n",
    "plt.title(f'Label: {random_label}')\n",
    "plt.axis('off')  # Turn off axis\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2 Data Preprocessing (10 pts):**\n",
    "\n",
    "In this step, you need to: \n",
    "\n",
    "(a)  Normalize the pixel values of images to be between 0 and 1. (5 pts) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pixel values of images to be between 0 and 1\n",
    "train_images_normalized = train_images / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "(b)  Convert the labels from categorical data into numerical values using one-hot encoding. (5 pts) \n",
    "\n",
    "hint: you can explore the eye function in Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to one-hot encoding\n",
    "def one_hot_encode(labels, num_classes):\n",
    "    num_labels = len(labels)\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    one_hot_encoded = np.zeros((num_labels, num_classes))\n",
    "    one_hot_encoded.flat[index_offset + labels.ravel()] = 1\n",
    "    return one_hot_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_classes = 10  # As there are 10 classes (0 to 9 for digits)\n",
    "train_labels_one_hot = one_hot_encode(train_labels, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3 Network Initialization (10 pts):**\n",
    "\n",
    "We will work with a neuron network with two hidden layers, using Sigmoid function as the activation functions for hidden \n",
    "layers and softmax activation function for the output layer. To finish this, you need to:\n",
    " \n",
    "(a)  Identify the auxiliary input including the Sigmoid function and its derivative and Softmax \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))  # for numerical stability\n",
    "    return e_x / e_x.sum(axis=-1, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(695)  # Setting the seed for reproducibility\n",
    "\n",
    "input_size = 784\n",
    "hidden_size1 = 128\n",
    "hidden_size2 = 64\n",
    "output_size = 10\n",
    "\n",
    "# Initialize weights and biases for the neural network\n",
    "weights_input_hidden1 = np.random.uniform(-0.1, 0.1, size=(input_size, hidden_size1))\n",
    "biases_hidden1 = np.zeros(hidden_size1)\n",
    "\n",
    "weights_hidden1_hidden2 = np.random.uniform(-0.1, 0.1, size=(hidden_size1, hidden_size2))\n",
    "biases_hidden2 = np.zeros(hidden_size2)\n",
    "\n",
    "weights_hidden2_output = np.random.uniform(-0.1, 0.1, size=(hidden_size2, output_size))\n",
    "biases_output = np.zeros(output_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4 Feed Forward (10 pts): In this step, you need to:**\n",
    "\n",
    "(a)  Define a function named feed_forward. Given an input x, it should output the sigmoid of wx+b \n",
    "where w and b indicates the weights and bias defined in step 2. (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(x, weights, biases):\n",
    "    layer_input = x\n",
    "    for i in range(len(weights)):\n",
    "        layer_output = np.dot(layer_input, weights[i]) + biases[i]\n",
    "        layer_input = sigmoid(layer_output)  # Using the sigmoid activation function\n",
    "    return layer_input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5 Back Propagation (15 pts): In this step, you need to implement the back \n",
    "propagation:**\n",
    "\n",
    "\n",
    "(a)  You need to compute the loss for the output layer first. Here, we use categorical cross entropy \n",
    "loss function given below for multi-class classification problem. (5 pts) Note, to achieve this, you \n",
    "need to first encode the categorical labels as numerical values using one-hot encoding finished \n",
    "in step 2. (5 pts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_crossentropy(y_true, y_pred):\n",
    "    n_samples = y_true.shape[0]\n",
    "    y_pred_clipped = np.clip(y_pred, 1e-12, 1 - 1e-12)\n",
    "    return -np.sum(y_true * np.log(y_pred_clipped)) / n_samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b)  Calculate the gradients for the weights and bias for each layer. Use the chain rule to compute \n",
    "gradients for previous layers. (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradients(layer_inputs, layer_outputs, weights, biases, prev_gradients):\n",
    "    # Gradient for the output layer\n",
    "    grad_output_layer = layer_outputs - prev_gradients\n",
    "\n",
    "    # Gradient for weights and biases in the output layer\n",
    "    weights_gradients_output = np.dot(layer_inputs.T, grad_output_layer)\n",
    "    biases_gradients_output = np.sum(grad_output_layer, axis=0)\n",
    "\n",
    "    # Gradients for the hidden layers using chain rule\n",
    "    grad_hidden = np.dot(grad_output_layer, weights.T) * sigmoid_derivative(layer_inputs)\n",
    "\n",
    "    # Gradients for weights and biases in hidden layers\n",
    "    weights_gradients_hidden = np.dot(layer_inputs.T, grad_hidden)\n",
    "    biases_gradients_hidden = np.sum(grad_hidden, axis=0)\n",
    "\n",
    "    return weights_gradients_output, biases_gradients_output, weights_gradients_hidden, biases_gradients_hidden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6 Model Training (15 pts):**\n",
    "\n",
    "In this step, you need to:\n",
    "\n",
    "(a)  Use mini-batch gradient descent to update the parameters including weights and bias. Notice \n",
    "that a complete training round consists of a feed forward process, back propagation and \n",
    "parameter update. Define the batch size = 128 and epoch = 100. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 100\n",
    "learning_rate = 0.01  # Set your learning rate\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, len(train_images_normalized), batch_size):\n",
    "        # Mini-batch creation\n",
    "        batch_images = train_images_normalized[i:i + batch_size]\n",
    "        batch_labels = train_labels_one_hot[i:i + batch_size]\n",
    "        \n",
    "        # Flatten the input images\n",
    "        batch_images_flattened = batch_images.reshape(batch_size, -1)  # Flatten each image to a 1D array\n",
    "\n",
    "        # Forward pass\n",
    "        layer_input = batch_images\n",
    "        layer_outputs = [layer_input]\n",
    "        for w, b in zip([weights_input_hidden1, weights_hidden1_hidden2, weights_hidden2_output],\n",
    "                        [biases_hidden1, biases_hidden2, biases_output]):\n",
    "            layer_input = np.dot(layer_input, w) + b\n",
    "            layer_output = sigmoid(layer_input)\n",
    "            layer_outputs.append(layer_output)\n",
    "\n",
    "        # Backward pass\n",
    "        gradients = compute_gradients(batch_images, layer_outputs[1], layer_outputs[2], layer_outputs[3], batch_labels)\n",
    "\n",
    "        # Update weights and biases\n",
    "        weights_hidden2_output -= learning_rate * gradients[0]\n",
    "        biases_output -= learning_rate * gradients[1]\n",
    "        weights_hidden1_hidden2 -= learning_rate * gradients[2]\n",
    "        biases_hidden2 -= learning_rate * gradients[3]\n",
    "        weights_input_hidden1 -= learning_rate * gradients[4]\n",
    "        biases_hidden1 -= learning_rate * gradients[5]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
